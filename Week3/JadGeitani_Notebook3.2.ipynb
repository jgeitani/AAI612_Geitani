{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ted7DkBVgrM"
      },
      "source": [
        "\n",
        "\n",
        "# AAI612: Deep Learning & its Applications\n",
        "\n",
        "\n",
        "*Notebook 3.2: Practice with Images*\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jgeitani/AAI612_Geitani/blob/main/Week3/JadGeitani_Notebook3.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5Bzn8SVgrR"
      },
      "source": [
        "# Image Classification with the MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN0HSwVWVgrU"
      },
      "source": [
        "Historically, the expert systems that were built to do classification similar this lab were extremely complicated, and people spent their careers building them (check out the references on the [official MNIST page](http://yann.lecun.com/exdb/mnist/) and the years milestones were reached)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4C74DtmVgrW"
      },
      "source": [
        "## The Problem: Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrA-p5i-VgrZ"
      },
      "source": [
        "In traditional programming, the programmer is able to articulate rules and conditions in their code that their program can then use to act in the correct way. This approach continues to work exceptionally well for a huge variety of problems.\n",
        "\n",
        "Image classification, which asks a program to correctly classify an image it has never seen before into its correct class, is near impossible to solve with traditional programming techniques. How could a programmer possibly define the rules and conditions to correctly classify a huge variety of images, especially taking into account images that they have never seen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wszw73_SVgrb"
      },
      "source": [
        "## The Solution: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppMcMK_kVgrd"
      },
      "source": [
        "Deep learning excels at pattern recognition by trial and error. By training a deep neural network with sufficient data, and providing the network with feedback on its performance via training, the network can identify, though a huge amount of iteration, its own set of conditions by which it can act in the correct way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFvX8bfDVgrf"
      },
      "source": [
        "## The MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0uF231MVgrg"
      },
      "source": [
        "In the history of deep learning, the accurate image classification of the [MNSIT dataset](http://yann.lecun.com/exdb/mnist/), a collection of 70,000 grayscale images of handwritten digits from 0 to 9, was a major development. While today the problem is considered trivial, doing image classification with MNIST has become a kind of \"Hello World\" for deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zi_AcIdVgri"
      },
      "source": [
        "Here are 40 of the images included in the MNIST dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ulru71XVgrj"
      },
      "source": [
        "<img src=\"https://github.com/harmanani/AAI612/blob/main/Week3/images/mnist.jpg?raw=1\" style=\"width: 600px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1i-OPsBVgrk"
      },
      "source": [
        "## Training and Validation Data and Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL_BMC7PVgrm"
      },
      "source": [
        "When working with images for deep learning, we need both the images themselves, usually denoted as `X`, and also, correct [labels](https://developers.google.com/machine-learning/glossary#label) for these images, usually denoted as `Y`. Furthermore, we need `X` and `Y` values both for *training* the model, and then, a separate set of `X` and `Y` values for *validating* the performance of the model after it has been trained. Therefore, we need 4 segments of data for the MNIST dataset:\n",
        "\n",
        "1. `x_train`: Images used for training the neural network\n",
        "2. `y_train`: Correct labels for the `x_train` images, used to evaluate the model's predictions during training\n",
        "3. `x_valid`: Images set aside for validating the performance of the model after it has been trained\n",
        "4. `y_valid`: Correct labels for the `x_valid` images, used to evaluate the model's predictions after it has been trained\n",
        "\n",
        "The process of preparing data for analysis is called [Data Engineering](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). To learn more about the differences between training data and validation data (as well as test data), check out [this article](https://machinelearningmastery.com/difference-test-validation-datasets/) by Jason Brownlee."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyz3GpKxVgro"
      },
      "source": [
        "## Loading the Data Into Memory (with Keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ET6JgcGVgrq"
      },
      "source": [
        "There are many [deep learning frameworks](https://developer.nvidia.com/deep-learning-frameworks), each with their own merits. In this workshop we will be working with [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner), and specifically with the [Keras API](https://keras.io/). Keras has many useful built in functions designed for the computer vision tasks. It is also a legitimate choice for deep learning in a professional setting due to its [readability](https://blog.pragmaticengineer.com/readable-code/) and efficiency, though it is not alone in this regard, and it is worth investigating a variety of frameworks when beginning a deep learning project.\n",
        "\n",
        "One of the many helpful features that Keras provides are modules containing many helper methods for [many common datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets), including MNIST.\n",
        "\n",
        "We will begin by loading the Keras dataset module for MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7kVivePWVgrs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myj8aXyeVgrx"
      },
      "source": [
        "With the `mnist` module, we can easily load the MNIST data, already partitioned into images and labels for both training and validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vb-haklkVgry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146249f9-1bdc-4d88-f250-a60f8095e3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# the data, split between train and validation sets\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPU4L88AVgrz"
      },
      "source": [
        "## Exploring the MNIST Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "435fhwi4Vgr0"
      },
      "source": [
        "We stated above that the MNIST dataset contained 70,000 grayscale images of handwritten digits. By executing the following cells, we can see that Keras has partitioned 60,000 of these images for training, and 10,000 for validation (after training), and also, that each image itself is a 2D array with the dimensions 28x28:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_NSC10jkVgr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0b59f8-f455-40e7-b264-8d826f2b2b8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e2F_bZt1Vgr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeeb66a7-11ac-4309-e57d-d16d4e89c3a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x_valid.shape\n",
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rWtH_TOVgr3"
      },
      "source": [
        "Furthermore, we can see that these 28x28 images are represented as a collection of unsigned 8-bit integer values between 0 and 255, the values corresponding with a pixel's grayscale value where `0` is black, `255` is white, and all other values are in between:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uXXTNv6MVgr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fd6865-59dc-4efb-fcdb-dab51ffd8ba4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bJvrreGLVgr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8176a6e2-99a9-4519-d79f-d58febcaa7cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zyuwyq0FVgr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56790e5-be2b-4a33-891a-900cebee6603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cgPlkN6kVgr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a8a20d44-ec66-44aa-b3e3-a3708953457f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-1dc39975-dde4-490b-a0ee-5bb068c1d287\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-1dc39975-dde4-490b-a0ee-5bb068c1d287 button').onclick = (e) => {\n",
              "        document.querySelector('#id-1dc39975-dde4-490b-a0ee-5bb068c1d287').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-1dc39975-dde4-490b-a0ee-5bb068c1d287 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mMSh1D0Vgr6"
      },
      "source": [
        "Using [Matplotlib](https://matplotlib.org/), we can render one of these grayscale images in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fg0Vdu08Vgr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "7b7571d4-ca36-4b81-dab8-5624c2713d36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c05f85a9210>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = x_train[0]\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO_7AcZdVgr7"
      },
      "source": [
        "In this way we can now see that this is a 28x28 pixel image of a 5. Or is it a 3? The answer is in the `y_train` data, which contains correct labels for the data. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2oJulKO4Vgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927092ca-6902-4ab4-b591-15cbf7da100a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJN_HJJ_Vgr8"
      },
      "source": [
        "## Preparing the Data for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc8fKUfUVgr8"
      },
      "source": [
        "In deep learning, it is common that data needs to be transformed to be in the ideal state for training. For this particular image classification problem, there are 3 tasks we should perform with the data in preparation for training:\n",
        "1. Flatten the image data, to simplify the image input into the model\n",
        "2. Normalize the image data, to make the image input values easier to work with for the model\n",
        "3. Categorize the labels, to make the label values easier to work with for the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kviTAqVzVgr8"
      },
      "source": [
        "### Flattening the Image Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXe_E6t_Vgr9"
      },
      "source": [
        "Though it's possible for a deep learning model to accept a 2-dimensional image (in our case 28x28 pixels), we're going to simplify things to start and [reshape](https://www.tensorflow.org/api_docs/python/tf/reshape) each image into a single array of 784 continuous pixels (note: 28x28 = 784). This is also called flattening the image.\n",
        "\n",
        "Here we accomplish this using the helper method `reshape`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wmfKrm7xVgr9"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_valid = x_valid.reshape(10000, 784)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmkLoJo4Vgr9"
      },
      "source": [
        "We can confirm that the image data has been reshaped and is now a collection of 1D arrays containing 784 pixel values each:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "N506ivldVgr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86b3c7e-4f9c-40e0-a538-54432bacd3b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CPOfMJjjVgr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f975a603-3af4-4b0a-c441-80f79d1520c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM1xoDN5VgsM"
      },
      "source": [
        "### Normalizing the Image Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNQ_7mNkVgsM"
      },
      "source": [
        "Deep learning models are better at dealing with floating point numbers between 0 and 1 (more on this topic later). Converting integer values to floating point values between 0 and 1 is called [normalization](https://developers.google.com/machine-learning/glossary#normalization), and a simple approach we will take here to normalize the data will be to divide all the pixel values (which if you recall are between 0 and 255) by 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RJ08MihfVgsM"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FEy5L6WVgsN"
      },
      "source": [
        "We can now see that the values are all floating point values between `0.0` and `1.0`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YV9QabqJVgsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5857ccc9-e0af-481d-9c01-7564025ff28b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "niF9Hk3OVgsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1037a5-000c-418f-994b-63dde8288ae7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3iKeu1AZVgsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee07161-728e-4255-a680-7540cac8dc2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuReW-SLVgsP"
      },
      "source": [
        "### Categorical Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EecC395pVgsP"
      },
      "source": [
        "Consider for a moment, if we were to ask, what is 7 - 2? Stating that the answer was 4 is closer than stating that the answer was 9. However, for this image classification problem, we don't want the neural network to learn this kind of reasoning: we just want it to select the correct category, and understand that if we have an image of the number 5, that guessing 4 is just as bad as guessing 9.\n",
        "\n",
        "As it stands, the labels for the images are integers between 0 and 9. Because these values represent a numerical range, the model might try to draw some conclusions about its performance based on how close to the correct numerical category it guesses.\n",
        "\n",
        "Therefore, we will do something to our data called categorical encoding. This kind of transformation modifies the data so that each value is a collection of all possible categories, with the actual category that this particular value is set as true.\n",
        "\n",
        "As a simple example, consider if we had 3 categories: red, blue, and green. For a given color, 2 of these categories would be false, and the other would be true:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU53M3tAVgsQ"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|True|False|False|\n",
        "|Green|False|False|True|\n",
        "|Blue|False|True|False|\n",
        "|Green|False|False|True|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEBQvkaKVgsQ"
      },
      "source": [
        "Rather than use \"True\" or \"False\", we could represent the same using binary, either 0 or 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLduwnmoVgsQ"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|1|0|0|\n",
        "|Green|0|0|1|\n",
        "|Blue|0|1|0|\n",
        "|Green|0|0|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4ptmQoVgsR"
      },
      "source": [
        "This is what categorical encoding is, transforming values which are intended to be understood as categorical labels into a representation that makes their categorical nature explicit to the model. Thus, if we were using these values for training, we would convert..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snyxj15eVgsR"
      },
      "source": [
        "```python\n",
        "values = ['red, green, blue, green']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE5D1ifeVgsS"
      },
      "source": [
        "... which a neural network would have a very difficult time making sense of, instead to:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "729twejnVgsS"
      },
      "source": [
        "```python\n",
        "values = [\n",
        "    [1, 0, 0],\n",
        "    [0, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1]\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cujPCv_sVgsT"
      },
      "source": [
        "### Categorically Encoding the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BaZrhcZVgsU"
      },
      "source": [
        "Keras provides a utility to [categorically encode values](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical), and here we use it to perform categorical encoding for both the training and validation labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "17GisudBVgsU"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "num_categories = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLzXAgEiVgsV"
      },
      "source": [
        "Here are the first 10 values of the training labels, which you can see have now been categorically encoded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2lODfYQQVgsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c523302-d39a-4a67-cad6-02c7788694f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_train[0:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnJG_SRsVgsW"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQZ6NO2EVgsW"
      },
      "source": [
        "With the data prepared for training, it is now time to create the model that we will train with the data. This first basic model will be made up of several *layers* and will be comprised of 3 main parts:\n",
        "\n",
        "1. An input layer, which will receive data in some expected format\n",
        "2. Several [hidden layers](https://developers.google.com/machine-learning/glossary#hidden-layer), each comprised of many *neurons*. Each [neuron](https://developers.google.com/machine-learning/glossary#neuron) will have the ability to affect the network's guess with its *weights*, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
        "3. An output layer, which will depict the network's guess for a given image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGhGxlPDVgsX"
      },
      "source": [
        "### Instantiating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYDQfsQBVgsY"
      },
      "source": [
        "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LTX4VKPUVgsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2c8005-cef9-4f48-be21-e75ebfb41d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with activation: linear\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6704 - loss: 1.0531 - val_accuracy: 0.8975 - val_loss: 0.3483\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8987 - loss: 0.3492 - val_accuracy: 0.9095 - val_loss: 0.3095\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.3109 - val_accuracy: 0.9178 - val_loss: 0.2908\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2895 - val_accuracy: 0.9147 - val_loss: 0.2889\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2827 - val_accuracy: 0.9166 - val_loss: 0.3006\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2778 - val_accuracy: 0.9204 - val_loss: 0.2843\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2720 - val_accuracy: 0.9228 - val_loss: 0.2701\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2667 - val_accuracy: 0.9242 - val_loss: 0.2668\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2618 - val_accuracy: 0.9232 - val_loss: 0.2738\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2636 - val_accuracy: 0.9176 - val_loss: 0.2840\n",
            "Training model with activation: relu\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6027 - loss: 1.3005 - val_accuracy: 0.8720 - val_loss: 0.4373\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8784 - loss: 0.4204 - val_accuracy: 0.8965 - val_loss: 0.3530\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.3516 - val_accuracy: 0.9094 - val_loss: 0.3155\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.3110 - val_accuracy: 0.9181 - val_loss: 0.2820\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9188 - loss: 0.2845 - val_accuracy: 0.9208 - val_loss: 0.2661\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.2597 - val_accuracy: 0.9309 - val_loss: 0.2441\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.2347 - val_accuracy: 0.9335 - val_loss: 0.2261\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9372 - loss: 0.2165 - val_accuracy: 0.9364 - val_loss: 0.2145\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.2028 - val_accuracy: 0.9430 - val_loss: 0.1922\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.1838 - val_accuracy: 0.9468 - val_loss: 0.1760\n",
            "Training model with activation: softmax\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1091 - loss: 2.3017 - val_accuracy: 0.1135 - val_loss: 2.3013\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1099 - loss: 2.3021 - val_accuracy: 0.1135 - val_loss: 2.3012\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1145 - loss: 2.3004 - val_accuracy: 0.2099 - val_loss: 2.2368\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2246 - loss: 2.0829 - val_accuracy: 0.2537 - val_loss: 1.8381\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.2599 - loss: 1.8183 - val_accuracy: 0.2682 - val_loss: 1.7678\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2711 - loss: 1.7568 - val_accuracy: 0.3027 - val_loss: 1.7329\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.3119 - loss: 1.7231 - val_accuracy: 0.3010 - val_loss: 1.7073\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.3130 - loss: 1.6970 - val_accuracy: 0.3176 - val_loss: 1.6871\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.3262 - loss: 1.6747 - val_accuracy: 0.3177 - val_loss: 1.6669\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.3314 - loss: 1.6553 - val_accuracy: 0.3383 - val_loss: 1.6273\n",
            "Training model with activation: swish\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.5832 - loss: 1.2726 - val_accuracy: 0.8750 - val_loss: 0.4259\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8798 - loss: 0.4083 - val_accuracy: 0.8990 - val_loss: 0.3498\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.3490 - val_accuracy: 0.9067 - val_loss: 0.3289\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.3195 - val_accuracy: 0.9121 - val_loss: 0.3076\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2947 - val_accuracy: 0.9151 - val_loss: 0.2947\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2863 - val_accuracy: 0.9209 - val_loss: 0.2787\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.2764 - val_accuracy: 0.9217 - val_loss: 0.2762\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.2620 - val_accuracy: 0.9274 - val_loss: 0.2503\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.2433 - val_accuracy: 0.9286 - val_loss: 0.2459\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.2419 - val_accuracy: 0.9315 - val_loss: 0.2357\n",
            "Training model with LeakyReLU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 1.1561 - val_accuracy: 0.8912 - val_loss: 0.3729\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8978 - loss: 0.3554 - val_accuracy: 0.9123 - val_loss: 0.3065\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2998 - val_accuracy: 0.9234 - val_loss: 0.2604\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2584 - val_accuracy: 0.9255 - val_loss: 0.2461\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.2351 - val_accuracy: 0.9367 - val_loss: 0.2100\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.2110 - val_accuracy: 0.9424 - val_loss: 0.1953\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1820 - val_accuracy: 0.9480 - val_loss: 0.1740\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1682 - val_accuracy: 0.9508 - val_loss: 0.1645\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.1520 - val_accuracy: 0.9563 - val_loss: 0.1470\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1346 - val_accuracy: 0.9557 - val_loss: 0.1468\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Activation, LeakyReLU, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define possible activation functions\n",
        "activations = ['linear', 'relu', 'softmax', 'swish']\n",
        "\n",
        "# Ensure the input shape is correct (batch_size, 28, 28)\n",
        "x_train = x_train.reshape(-1, 28, 28).astype(\"float32\") / 255.0\n",
        "x_valid = x_valid.reshape(-1, 28, 28).astype(\"float32\") / 255.0\n",
        "\n",
        "# Train models with different activations\n",
        "results = {}\n",
        "\n",
        "for act in activations:\n",
        "    print(f\"Training model with activation: {act}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(28, 28)),  # Ensure explicit input shape\n",
        "        Flatten(),\n",
        "        Dense(128, activation=act),\n",
        "        Dense(64, activation=act),\n",
        "        Dense(10, activation='softmax')  # Output layer with softmax for classification\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "    # Early Stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=10,  # Increased number of epochs for better learning\n",
        "        validation_data=(x_valid, y_valid),\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping]  # Apply EarlyStopping\n",
        "    )\n",
        "\n",
        "    results[act] = history.history\n",
        "\n",
        "# Train with Leaky ReLU separately\n",
        "print(\"Training model with LeakyReLU\")\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(64),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    verbose=1,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "results['LeakyReLU'] = history.history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okaxH31GVgsb"
      },
      "source": [
        "### Creating the Input Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwOgVqReVgsb"
      },
      "source": [
        "Next, we will add the input layer. This layer will be *densely connected*, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Keras's [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KiDxgjEgVgsc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FDq4m8tVgsc"
      },
      "source": [
        "The `units` argument specifies the number of neurons in the layer. We are going to use `512` which we have chosen from experimentation. Choosing the correct number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset. Try playing around with this value later to see how it affects training and to start developing a sense for what this number means.\n",
        "\n",
        "We will learn more about activation functions later, but for now, we will use the `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function.\n",
        "\n",
        "The `input_shape` value specifies the shape of the incoming data which in our situation is a 1D array of 784 values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XnR8suOXVgsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09eca285-fbb4-49ff-b5ca-cef46313f56e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APEep-8qVgse"
      },
      "source": [
        "### Creating the Hidden Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TceI5ibkVgse"
      },
      "source": [
        "Now we will add an additional densely connected layer. Again, much more will be said about these later, but for now know that these layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PkLCnX-QVgsf"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 512, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVMSgLdUVgsf"
      },
      "source": [
        "### Creating the Output Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rVNqWiMVgsg"
      },
      "source": [
        "Finally, we will add an output layer. This layer uses the activation function `softmax` which will result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 10 possible categories, there will be 10 outputs. Each output gives the model's guess (a probability) that the image belongs to that specific class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AYgdwI0MVgsg"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q8gsLJ2Vgsg"
      },
      "source": [
        "### Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzM7q9cUVgsh"
      },
      "source": [
        "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S3eoKfAnVgsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "222f8c48-cb8a-4ca9-ecca-dd838d31c45b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m5,632\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m601,578\u001b[0m (2.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">601,578</span> (2.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m382,804\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,804</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m218,774\u001b[0m (854.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,774</span> (854.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucQHqPLKVgsi"
      },
      "source": [
        "Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aek38urgVgsi"
      },
      "source": [
        "### Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1gECNH2Vgsj"
      },
      "source": [
        "Again, more details are to follow, but the final step we need to do before we can actually train our model with data is to [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) it. Here we specify a [loss function](https://developers.google.com/machine-learning/glossary#loss) which will be used for the model to understand how well it is performing during training. We also specify that we would like to track `accuracy` while the model trains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Zq_BimI7Vgsj"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u51rZDpVgsk"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGSjBgGzVgsk"
      },
      "source": [
        "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
        "\n",
        "\"Training a model with data\" is often also called \"fitting a model to data.\" Put this latter way, it highlights that the shape of the model changes over time to more accurately understand the data that it is being given.\n",
        "\n",
        "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
        "\n",
        "* The training data\n",
        "* The labels for the training data\n",
        "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
        "* The validation or test data, and its labels\n",
        "\n",
        "Run the cell below to train the model. We will discuss its output after the training completes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IcIET1JQVgsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc0b4a3-ccd3-4ada-f60d-54c8b3156cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with activation: linear\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 1.0590 - val_accuracy: 0.8975 - val_loss: 0.3517\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.3427 - val_accuracy: 0.9139 - val_loss: 0.3053\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.3053 - val_accuracy: 0.9156 - val_loss: 0.2878\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2878 - val_accuracy: 0.9197 - val_loss: 0.2873\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2828 - val_accuracy: 0.9219 - val_loss: 0.2746\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2740 - val_accuracy: 0.9232 - val_loss: 0.2709\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2734 - val_accuracy: 0.9230 - val_loss: 0.2687\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2720 - val_accuracy: 0.9228 - val_loss: 0.2810\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2682 - val_accuracy: 0.9230 - val_loss: 0.2745\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.2641 - val_accuracy: 0.9214 - val_loss: 0.2749\n",
            "Training model with activation: relu\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5775 - loss: 1.3308 - val_accuracy: 0.8680 - val_loss: 0.4462\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.4219 - val_accuracy: 0.8955 - val_loss: 0.3642\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.3393 - val_accuracy: 0.9107 - val_loss: 0.3067\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9122 - loss: 0.3048 - val_accuracy: 0.9197 - val_loss: 0.2778\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2726 - val_accuracy: 0.9216 - val_loss: 0.2581\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 0.2513 - val_accuracy: 0.9277 - val_loss: 0.2483\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.2300 - val_accuracy: 0.9326 - val_loss: 0.2197\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.2041 - val_accuracy: 0.9389 - val_loss: 0.2035\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9420 - loss: 0.1972 - val_accuracy: 0.9441 - val_loss: 0.1882\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1790 - val_accuracy: 0.9458 - val_loss: 0.1778\n",
            "Training model with activation: softmax\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1096 - loss: 2.3018 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1103 - loss: 2.3016 - val_accuracy: 0.1135 - val_loss: 2.3012\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1118 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3000\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1463 - loss: 2.2664 - val_accuracy: 0.2500 - val_loss: 1.9972\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.2580 - loss: 1.9677 - val_accuracy: 0.2848 - val_loss: 1.8726\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2852 - loss: 1.8669 - val_accuracy: 0.3069 - val_loss: 1.7939\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.3089 - loss: 1.7945 - val_accuracy: 0.3457 - val_loss: 1.7359\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3621 - loss: 1.7216 - val_accuracy: 0.4712 - val_loss: 1.5002\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.4768 - loss: 1.4815 - val_accuracy: 0.4984 - val_loss: 1.3687\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5016 - loss: 1.3748 - val_accuracy: 0.5100 - val_loss: 1.3077\n",
            "Training model with activation: swish\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 1.2467 - val_accuracy: 0.8802 - val_loss: 0.4100\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8836 - loss: 0.4085 - val_accuracy: 0.8984 - val_loss: 0.3514\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.3571 - val_accuracy: 0.9053 - val_loss: 0.3240\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.3311 - val_accuracy: 0.9126 - val_loss: 0.3025\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.3029 - val_accuracy: 0.9176 - val_loss: 0.2904\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2918 - val_accuracy: 0.9199 - val_loss: 0.2787\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2847 - val_accuracy: 0.9196 - val_loss: 0.2770\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.2662 - val_accuracy: 0.9240 - val_loss: 0.2618\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.2551 - val_accuracy: 0.9267 - val_loss: 0.2501\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.2435 - val_accuracy: 0.9281 - val_loss: 0.2423\n",
            "Training model with LeakyReLU\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6216 - loss: 1.2034 - val_accuracy: 0.8800 - val_loss: 0.4025\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8913 - loss: 0.3693 - val_accuracy: 0.9125 - val_loss: 0.3050\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2950 - val_accuracy: 0.9189 - val_loss: 0.2718\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9219 - loss: 0.2661 - val_accuracy: 0.9289 - val_loss: 0.2465\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.2339 - val_accuracy: 0.9383 - val_loss: 0.2084\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.1985 - val_accuracy: 0.9447 - val_loss: 0.1844\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.1728 - val_accuracy: 0.9474 - val_loss: 0.1710\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1577 - val_accuracy: 0.9534 - val_loss: 0.1559\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9583 - loss: 0.1415 - val_accuracy: 0.9583 - val_loss: 0.1379\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1282 - val_accuracy: 0.9618 - val_loss: 0.1280\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Activation, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define possible activation functions\n",
        "activations = ['linear', 'relu', 'softmax', 'swish']\n",
        "\n",
        "# Train models with different activations\n",
        "results = {}\n",
        "\n",
        "for act in activations:\n",
        "    print(f\"Training model with activation: {act}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),  # Flattening the input image\n",
        "        Dense(128, activation=act),\n",
        "        Dense(64, activation=act),\n",
        "        Dense(10, activation='softmax')  # Output layer with softmax for classification\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "    # Early Stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=10,  # Increased number of epochs for better learning\n",
        "        validation_data=(x_valid, y_valid),\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping]  # Apply EarlyStopping\n",
        "    )\n",
        "\n",
        "    results[act] = history.history\n",
        "\n",
        "# Train with Leaky ReLU separately\n",
        "print(\"Training model with LeakyReLU\")\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(64),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    verbose=1,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "results['LeakyReLU'] = history.history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fe68BjrRVgsm"
      },
      "outputs": [],
      "source": [
        "chart_x = range(1,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YjJV1Ds9Vgsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de415e4-aef2-4920-e8c1-ee88c0ac678c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
          ]
        }
      ],
      "source": [
        "chart_y_train = history.history['loss']\n",
        "chart_y_test = history.history['val_loss']\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zQQ9YcWUVgsm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "fecc1955-30c0-4997-853d-0d5279358258"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure all arrays are the same length\n",
        "min_len = min(len(chart_x), len(chart_y_train), len(chart_y_test))\n",
        "\n",
        "# Slice arrays to match the shortest one\n",
        "chart_x = chart_x[:min_len]\n",
        "chart_y_train = chart_y_train[:min_len]\n",
        "chart_y_test = chart_y_test[:min_len]\n",
        "\n",
        "def plot_learning():\n",
        "    plt.plot(chart_x, chart_y_train, 'r-', label='training error')\n",
        "    plt.plot(chart_x, chart_y_test, 'b-', label='test error')\n",
        "    plt.xlabel('Training Epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_learning()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEDWqn7WVgsn"
      },
      "source": [
        "### Observing Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7YvMeLCVgso"
      },
      "source": [
        "For each of the 5 epochs, notice the `accuracy` and `val_accuracy` scores. `accuracy` states how well the model did for the epoch on all the training data. `val_accuracy` states how well the model did on the validation data, which if you recall, was not used at all for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV9TF7ghVgso"
      },
      "source": [
        "The model did quite well! The accuracy quickly reached close to 100%, as did the validation accuracy. We now have a model that can be used to accurately detect and classify hand-written images.\n",
        "\n",
        "The next step would be to use this model to classify new not-yet-seen handwritten images. This is called [inference](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). We'll explore the process of inference in a later exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqp5n1IVVgsq"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELGkAOPoVgsr"
      },
      "source": [
        "MNIST is not only useful for its historical influence on Computer Vision, but it's also a great [benchmark](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf) and debugging tool."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}