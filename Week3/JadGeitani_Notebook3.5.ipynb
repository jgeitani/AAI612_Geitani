{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8SzUv3PQvOd"
      },
      "source": [
        "\n",
        "\n",
        "# AAI612: Deep Learning & its Applications\n",
        "\n",
        "\n",
        "*Notebook 3.5: Detecting Breast Cancer*\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jgeitani/AAI612_Geitani/blob/main/Week3/JadGeitani_Notebook3.5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdE0rhNHQvOh"
      },
      "source": [
        "# Breast Cancer Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJe5QmolQvOi"
      },
      "source": [
        "Breast cancer is the most common malignancy among women, accounting for nearly 1 in 3 cancers diagnosed among women in the United States, and it is the second leading cause of cancer death among women. Breast Cancer occurs as a results of abnormal growth of cells in the breast tissue, commonly referred to as a Tumor. A tumor does not mean cancer - tumors can be benign (not cancerous), pre-malignant (pre-cancerous), or malignant (cancerous). Tests such as MRI, mammogram, ultrasound and biopsy are commonly used to diagnose breast cancer performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVi6zTD9QvOj"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcNZdoCpQvOj"
      },
      "source": [
        "This is an analysis of the Breast Cancer Wisconsin (Diagnostic) [DataSet](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). This data set was created by Dr. William H. Wolberg, physician at the University Of Wisconsin Hospital at Madison, Wisconsin,USA. To create the dataset Dr. Wolberg used fluid samples, taken from patients with solid breast masses and an easy-to-use graphical computer program called Xcyt, which is capable of perform the analysis of cytological features based on a digital scan. The program uses a curve-fitting algorithm, to compute ten features from each one of the cells in the sample, than it calculates the mean value, extreme value and standard error of each feature for the image, returning a 30 real-valuated vector\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "- ID number\n",
        "- Diagnosis (M = malignant, B = benign) 3-32\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "1) radius (mean of distances from center to points on the perimeter)\n",
        "2) texture (standard deviation of gray-scale values)\n",
        "3) perimeter\n",
        "4) area\n",
        "5) smoothness (local variation in radius lengths)\n",
        "6) compactness (perimeter^2 / area - 1.0)\n",
        "7) concavity (severity of concave portions of the contour)\n",
        "8) concave points (number of concave portions of the contour)\n",
        "9) symmetry\n",
        "10) fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
        "\n",
        "All feature values are recoded with four significant digits.  There are no missing attribute values.  The class distribution is 357 benign and 212 malignant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQayWmHoQvOj"
      },
      "source": [
        "## The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZNV9o0-QvOk"
      },
      "source": [
        "The objective is to classify whether the breast cancer is benign or malignant.  Let us start by importing the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pUpSD35dQvOk"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BFxFHohXQvOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "e75bd91d-ce13-4b94-def5-e284a96b046b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "5    843786         M        12.45         15.70           82.57      477.1   \n",
              "6    844359         M        18.25         19.98          119.60     1040.0   \n",
              "7  84458202         M        13.71         20.83           90.20      577.9   \n",
              "8    844981         M        13.00         21.82           87.50      519.8   \n",
              "9  84501001         M        12.46         24.04           83.97      475.9   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760         0.30010              0.14710   \n",
              "1          0.08474           0.07864         0.08690              0.07017   \n",
              "2          0.10960           0.15990         0.19740              0.12790   \n",
              "3          0.14250           0.28390         0.24140              0.10520   \n",
              "4          0.10030           0.13280         0.19800              0.10430   \n",
              "5          0.12780           0.17000         0.15780              0.08089   \n",
              "6          0.09463           0.10900         0.11270              0.07400   \n",
              "7          0.11890           0.16450         0.09366              0.05985   \n",
              "8          0.12730           0.19320         0.18590              0.09353   \n",
              "9          0.11860           0.23960         0.22730              0.08543   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "5  ...          23.75           103.40       741.6            0.1791   \n",
              "6  ...          27.66           153.20      1606.0            0.1442   \n",
              "7  ...          28.14           110.60       897.0            0.1654   \n",
              "8  ...          30.73           106.20       739.3            0.1703   \n",
              "9  ...          40.68            97.65       711.4            0.1853   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "5             0.5249           0.5355                0.1741          0.3985   \n",
              "6             0.2576           0.3784                0.1932          0.3063   \n",
              "7             0.3682           0.2678                0.1556          0.3196   \n",
              "8             0.5401           0.5390                0.2060          0.4378   \n",
              "9             1.0580           1.1050                0.2210          0.4366   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "5                  0.12440          NaN  \n",
              "6                  0.08368          NaN  \n",
              "7                  0.11510          NaN  \n",
              "8                  0.10720          NaN  \n",
              "9                  0.20750          NaN  \n",
              "\n",
              "[10 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6199a400-ac58-4783-a29d-57698f4537a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>843786</td>\n",
              "      <td>M</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>...</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>844359</td>\n",
              "      <td>M</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>...</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84458202</td>\n",
              "      <td>M</td>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>...</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>844981</td>\n",
              "      <td>M</td>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>...</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>84501001</td>\n",
              "      <td>M</td>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>...</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6199a400-ac58-4783-a29d-57698f4537a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6199a400-ac58-4783-a29d-57698f4537a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6199a400-ac58-4783-a29d-57698f4537a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33b8a90e-e146-4b6b-8b96-96de82ce2b85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33b8a90e-e146-4b6b-8b96-96de82ce2b85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33b8a90e-e146-4b6b-8b96-96de82ce2b85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/harmanani/AAI612/main/Week3/breast_cancer/data.csv')\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YX9pGTiuQvOl"
      },
      "outputs": [],
      "source": [
        "# Deelete the last column!\n",
        "del data['Unnamed: 32']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sibuhou-QvOm"
      },
      "source": [
        "## The Solution: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ggvNYu_QvOm"
      },
      "source": [
        "Read features and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N2aMaOgJQvOn"
      },
      "outputs": [],
      "source": [
        "#Skip the first two columns: The ID and the diagnosis\n",
        "X = data.iloc[:, 2:].values\n",
        "\n",
        "# Now, read the diagnosis\n",
        "y = data.iloc[:, 1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS8sh9OcQvOn"
      },
      "source": [
        "Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "INq8VPAAQvOn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "y = labelencoder_X_1.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsRr-7dyQvOn"
      },
      "source": [
        "Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5FQas_S6QvOo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2mmbSuHQvOo"
      },
      "source": [
        "## Exploring the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g7nRD91cQvOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "176d6aa3-87ab-4bd9-95d9-fb221f237472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
              "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
              "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
              "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
              "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
              "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
              "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
              "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
              "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
              "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
              "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
              "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
              "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
              "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
              "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
              "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
              "\n",
              "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "count   569.000000        569.000000         569.000000       569.000000   \n",
              "mean    880.583128          0.132369           0.254265         0.272188   \n",
              "std     569.356993          0.022832           0.157336         0.208624   \n",
              "min     185.200000          0.071170           0.027290         0.000000   \n",
              "25%     515.300000          0.116600           0.147200         0.114500   \n",
              "50%     686.500000          0.131300           0.211900         0.226700   \n",
              "75%    1084.000000          0.146000           0.339100         0.382900   \n",
              "max    4254.000000          0.222600           1.058000         1.252000   \n",
              "\n",
              "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "count            569.000000      569.000000               569.000000  \n",
              "mean               0.114606        0.290076                 0.083946  \n",
              "std                0.065732        0.061867                 0.018061  \n",
              "min                0.000000        0.156500                 0.055040  \n",
              "25%                0.064930        0.250400                 0.071460  \n",
              "50%                0.099930        0.282200                 0.080040  \n",
              "75%                0.161400        0.317900                 0.092080  \n",
              "max                0.291000        0.663800                 0.207500  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b27b25a-910b-4781-af76-af9a689ecb25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>...</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>...</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>...</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>...</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>...</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>...</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b27b25a-910b-4781-af76-af9a689ecb25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b27b25a-910b-4781-af76-af9a689ecb25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b27b25a-910b-4781-af76-af9a689ecb25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-21eea549-e0a8-432c-a1bf-445af789a615\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21eea549-e0a8-432c-a1bf-445af789a615')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-21eea549-e0a8-432c-a1bf-445af789a615 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g6qtluGkQvOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9edfd4fe-70bc-4dba-dd2f-4faa97351864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           int64\n",
              "diagnosis                   object\n",
              "radius_mean                float64\n",
              "texture_mean               float64\n",
              "perimeter_mean             float64\n",
              "area_mean                  float64\n",
              "smoothness_mean            float64\n",
              "compactness_mean           float64\n",
              "concavity_mean             float64\n",
              "concave points_mean        float64\n",
              "symmetry_mean              float64\n",
              "fractal_dimension_mean     float64\n",
              "radius_se                  float64\n",
              "texture_se                 float64\n",
              "perimeter_se               float64\n",
              "area_se                    float64\n",
              "smoothness_se              float64\n",
              "compactness_se             float64\n",
              "concavity_se               float64\n",
              "concave points_se          float64\n",
              "symmetry_se                float64\n",
              "fractal_dimension_se       float64\n",
              "radius_worst               float64\n",
              "texture_worst              float64\n",
              "perimeter_worst            float64\n",
              "area_worst                 float64\n",
              "smoothness_worst           float64\n",
              "compactness_worst          float64\n",
              "concavity_worst            float64\n",
              "concave points_worst       float64\n",
              "symmetry_worst             float64\n",
              "fractal_dimension_worst    float64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diagnosis</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1Ef9RNAmQvOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd2e994-7049-4221-9dba-68f12a60bdb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M9eCWA8FQvOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71028ed-c11f-419c-8d97-654e7bfd7247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_valid.shape\n",
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7GVYueRQvOp"
      },
      "source": [
        "Furthermore, we can see that these 28x28 images are represented as a collection of unsigned 8-bit integer values between 0 and 255, the values corresponding with a pixel's grayscale value where `0` is black, `255` is white, and all other values are in between:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sKyHet2nQvOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdeb09d-a124-4061-9a5e-11b371c6e77c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5geZjk6wQvOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1716e00-3322-4fd4-886f-09de6c09ef4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Nd1fWqUkQvOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15aa4892-334b-436e-ef74-05f462f42fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4254.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RNXOpnDdQvOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f515d2f9-36f1-48df-ff96-d4e34f7e5e26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.005e+01, 1.753e+01, 6.441e+01, 3.108e+02, 1.007e-01, 7.326e-02,\n",
              "       2.511e-02, 1.775e-02, 1.890e-01, 6.331e-02, 2.619e-01, 2.015e+00,\n",
              "       1.778e+00, 1.685e+01, 7.803e-03, 1.449e-02, 1.690e-02, 8.043e-03,\n",
              "       2.100e-02, 2.778e-03, 1.116e+01, 2.684e+01, 7.198e+01, 3.840e+02,\n",
              "       1.402e-01, 1.402e-01, 1.055e-01, 6.499e-02, 2.894e-01, 7.664e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HKu7udmGQvOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ce596049-ca02-417a-8b3e-8458d6331075"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "ax = sns.countplot(x=data[\"diagnosis\"], width=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AMHMHTwQvOq"
      },
      "source": [
        "### Scaling!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxJGIj0hQvOq"
      },
      "source": [
        "Let us scale the features!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vkugSVD3QvOq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_valid = sc.transform(X_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbZFwqhcQvOq"
      },
      "source": [
        "And now notice the difference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SvNxyQg9QvOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c06237c-8e7f-4026-a9f8-ce2bf8ea47ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.15036482, -0.39064196, -1.12855021, -0.95876358,  0.3109837 ,\n",
              "       -0.5959945 , -0.80259612, -0.80249002,  0.29453906,  0.0942515 ,\n",
              "       -0.4950523 ,  1.48720153, -0.51448782, -0.49154005,  0.28149837,\n",
              "       -0.60451206, -0.46900701, -0.61170002,  0.05798237, -0.35763702,\n",
              "       -1.0431756 ,  0.21353282, -1.0360446 , -0.84880771,  0.34249851,\n",
              "       -0.73009743, -0.81232053, -0.75798367, -0.01614761, -0.38503402])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvKahwZrQvOr"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDJnrnTQQvOr"
      },
      "source": [
        "With the data prepared for training, it is now time to create the model that we will train with the data. This first basic model will be made up of several *layers* and will be comprised of 3 main parts:\n",
        "\n",
        "1. An input layer, which will receive data in some expected format\n",
        "2. Several [hidden layers](https://developers.google.com/machine-learning/glossary#hidden-layer), each comprised of many *neurons*. Each [neuron](https://developers.google.com/machine-learning/glossary#neuron) will have the ability to affect the network's guess with its *weights*, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
        "3. An output layer, which will output the prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYATZSreQvOr"
      },
      "source": [
        "### Instantiating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nwFPWMBQvOr"
      },
      "source": [
        "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iTNa1p2BQvOr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR_qi_ulQvOs"
      },
      "source": [
        "### Creating the Input Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI4lSes-QvOx"
      },
      "source": [
        "Next, we will add the input layer. This layer will be *densely connected*, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Keras's [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Fc5hlHZmQvOx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU-v4f6qQvOx"
      },
      "source": [
        "We will learn more about activation functions later, but for now, we will use the `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sNlWeH5eQvOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0be056-3315-400f-f6ef-5a0a250ae763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.add(Dense(units=30, activation='relu', input_shape=(30,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xWxPXtxQvOy"
      },
      "source": [
        "Adding dropout to prevent overfitting.  More about this one later :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gdM4pOKlQvOy"
      },
      "outputs": [],
      "source": [
        "model.add(Dropout(rate=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HONUd0JgQvOy"
      },
      "source": [
        "### Creating the Hidden Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azhWBMWqQvOy"
      },
      "source": [
        "Now we will add an additional densely connected layer. Again, much more will be said about these later, but for now know that these layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JNE9Sv8pQvOy"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 16, activation='relu'))\n",
        "model.add(Dropout(rate=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-va84lPQvOz"
      },
      "source": [
        "### Creating the Output Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl7xZSkJQvOz"
      },
      "source": [
        "Finally, we will add an output layer. This layer uses the activation function `sigmoid` which will result with an output probability between 0 and 1.  The reason is that this is a classification problem and we the prediction is the highest value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RFV2JilHQvOz"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLZxL9ZiQvOz"
      },
      "source": [
        "### Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D_9oAziQvOz"
      },
      "source": [
        "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e0dj10tBQvO0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "69d2a410-5724-4573-9819-ce2c897c710e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m930\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,443\u001b[0m (5.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,443</span> (5.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,443\u001b[0m (5.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,443</span> (5.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce1iXpNSQvO0"
      },
      "source": [
        "Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L30s5dStQvO0"
      },
      "source": [
        "### Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3HQEC2UQvO0"
      },
      "source": [
        "Again, more details are to follow, but the final step we need to do before we can actually train our model with data is to [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) it. Here we specify a [loss function](https://developers.google.com/machine-learning/glossary#loss) which will be used for the model to understand how well it is performing during training. We also specify that we would like to track `accuracy` while the model trains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jPHJIiM3QvO0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGn_Oa9ZQvO1"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTUa8kL2QvO1"
      },
      "source": [
        "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
        "\n",
        "\"Training a model with data\" is often also called \"fitting a model to data.\" Put this latter way, it highlights that the shape of the model changes over time to more accurately understand the data that it is being given.\n",
        "\n",
        "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
        "\n",
        "* The training data\n",
        "* The labels for the training data\n",
        "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
        "* The validation or test data, and its labels\n",
        "\n",
        "Run the cell below to train the model. We will discuss its output after the training completes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "af1Lv4qkQvO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f853b7-3464-4369-8d72-b484c69b4fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.5878 - loss: 0.7276 - val_accuracy: 0.6930 - val_loss: 0.5081\n",
            "Epoch 2/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7740 - loss: 0.4578 - val_accuracy: 0.8947 - val_loss: 0.3415\n",
            "Epoch 3/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8814 - loss: 0.3197 - val_accuracy: 0.9561 - val_loss: 0.2594\n",
            "Epoch 4/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9122 - loss: 0.2616 - val_accuracy: 0.9561 - val_loss: 0.2123\n",
            "Epoch 5/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9356 - loss: 0.2361 - val_accuracy: 0.9561 - val_loss: 0.1841\n",
            "Epoch 6/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9594 - loss: 0.1638 - val_accuracy: 0.9561 - val_loss: 0.1635\n",
            "Epoch 7/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9533 - loss: 0.1870 - val_accuracy: 0.9474 - val_loss: 0.1490\n",
            "Epoch 8/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9647 - loss: 0.1358 - val_accuracy: 0.9474 - val_loss: 0.1383\n",
            "Epoch 9/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9759 - loss: 0.1126 - val_accuracy: 0.9474 - val_loss: 0.1286\n",
            "Epoch 10/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9820 - loss: 0.0934 - val_accuracy: 0.9561 - val_loss: 0.1225\n",
            "Epoch 11/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9615 - loss: 0.1141 - val_accuracy: 0.9474 - val_loss: 0.1175\n",
            "Epoch 12/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9676 - loss: 0.1000 - val_accuracy: 0.9474 - val_loss: 0.1132\n",
            "Epoch 13/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9603 - loss: 0.1298 - val_accuracy: 0.9474 - val_loss: 0.1099\n",
            "Epoch 14/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9799 - loss: 0.0908 - val_accuracy: 0.9561 - val_loss: 0.1078\n",
            "Epoch 15/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9702 - loss: 0.0998 - val_accuracy: 0.9561 - val_loss: 0.1051\n",
            "Epoch 16/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9814 - loss: 0.0861 - val_accuracy: 0.9561 - val_loss: 0.1035\n",
            "Epoch 17/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9880 - loss: 0.0811 - val_accuracy: 0.9561 - val_loss: 0.1030\n",
            "Epoch 18/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9876 - loss: 0.0567 - val_accuracy: 0.9561 - val_loss: 0.1015\n",
            "Epoch 19/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0843 - val_accuracy: 0.9561 - val_loss: 0.0999\n",
            "Epoch 20/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9730 - loss: 0.0673 - val_accuracy: 0.9561 - val_loss: 0.0999\n",
            "Epoch 21/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9873 - loss: 0.0528 - val_accuracy: 0.9561 - val_loss: 0.0989\n",
            "Epoch 22/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9733 - loss: 0.0742 - val_accuracy: 0.9561 - val_loss: 0.0990\n",
            "Epoch 23/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9817 - loss: 0.0726 - val_accuracy: 0.9561 - val_loss: 0.0998\n",
            "Epoch 24/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9920 - loss: 0.0521 - val_accuracy: 0.9561 - val_loss: 0.1011\n",
            "Epoch 25/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9877 - loss: 0.0528 - val_accuracy: 0.9561 - val_loss: 0.0993\n",
            "Epoch 26/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9894 - loss: 0.0519 - val_accuracy: 0.9561 - val_loss: 0.0983\n",
            "Epoch 27/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9826 - loss: 0.0622 - val_accuracy: 0.9561 - val_loss: 0.0990\n",
            "Epoch 28/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9926 - loss: 0.0405 - val_accuracy: 0.9561 - val_loss: 0.0981\n",
            "Epoch 29/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9849 - loss: 0.0554 - val_accuracy: 0.9561 - val_loss: 0.1003\n",
            "Epoch 30/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9808 - loss: 0.0611 - val_accuracy: 0.9561 - val_loss: 0.1040\n",
            "Epoch 31/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9840 - loss: 0.0634 - val_accuracy: 0.9561 - val_loss: 0.1056\n",
            "Epoch 32/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0676 - val_accuracy: 0.9561 - val_loss: 0.1056\n",
            "Epoch 33/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0366 - val_accuracy: 0.9561 - val_loss: 0.1051\n",
            "Epoch 34/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0510 - val_accuracy: 0.9561 - val_loss: 0.1081\n",
            "Epoch 35/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0301 - val_accuracy: 0.9649 - val_loss: 0.1088\n",
            "Epoch 36/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0450 - val_accuracy: 0.9649 - val_loss: 0.1098\n",
            "Epoch 37/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0406 - val_accuracy: 0.9561 - val_loss: 0.1082\n",
            "Epoch 38/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0400 - val_accuracy: 0.9561 - val_loss: 0.1107\n",
            "Epoch 39/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0358 - val_accuracy: 0.9561 - val_loss: 0.1118\n",
            "Epoch 40/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0302 - val_accuracy: 0.9561 - val_loss: 0.1111\n",
            "Epoch 41/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0360 - val_accuracy: 0.9561 - val_loss: 0.1124\n",
            "Epoch 42/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0517 - val_accuracy: 0.9649 - val_loss: 0.1135\n",
            "Epoch 43/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0291 - val_accuracy: 0.9561 - val_loss: 0.1125\n",
            "Epoch 44/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0255 - val_accuracy: 0.9561 - val_loss: 0.1126\n",
            "Epoch 45/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0330 - val_accuracy: 0.9561 - val_loss: 0.1140\n",
            "Epoch 46/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0432 - val_accuracy: 0.9561 - val_loss: 0.1114\n",
            "Epoch 47/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.0498 - val_accuracy: 0.9561 - val_loss: 0.1208\n",
            "Epoch 48/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.0312 - val_accuracy: 0.9561 - val_loss: 0.1239\n",
            "Epoch 49/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0257 - val_accuracy: 0.9561 - val_loss: 0.1252\n",
            "Epoch 50/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0205 - val_accuracy: 0.9649 - val_loss: 0.1266\n",
            "Epoch 51/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0254 - val_accuracy: 0.9649 - val_loss: 0.1289\n",
            "Epoch 52/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0467 - val_accuracy: 0.9649 - val_loss: 0.1292\n",
            "Epoch 53/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0371 - val_accuracy: 0.9649 - val_loss: 0.1262\n",
            "Epoch 54/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0199 - val_accuracy: 0.9649 - val_loss: 0.1229\n",
            "Epoch 55/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0154 - val_accuracy: 0.9649 - val_loss: 0.1325\n",
            "Epoch 56/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0279 - val_accuracy: 0.9737 - val_loss: 0.1346\n",
            "Epoch 57/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0353 - val_accuracy: 0.9649 - val_loss: 0.1345\n",
            "Epoch 58/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0285 - val_accuracy: 0.9649 - val_loss: 0.1323\n",
            "Epoch 59/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0231 - val_accuracy: 0.9649 - val_loss: 0.1316\n",
            "Epoch 60/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0262 - val_accuracy: 0.9649 - val_loss: 0.1293\n",
            "Epoch 61/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0386 - val_accuracy: 0.9649 - val_loss: 0.1271\n",
            "Epoch 62/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0404 - val_accuracy: 0.9649 - val_loss: 0.1237\n",
            "Epoch 63/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0230 - val_accuracy: 0.9649 - val_loss: 0.1197\n",
            "Epoch 64/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0217 - val_accuracy: 0.9649 - val_loss: 0.1234\n",
            "Epoch 65/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0186 - val_accuracy: 0.9649 - val_loss: 0.1233\n",
            "Epoch 66/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0347 - val_accuracy: 0.9649 - val_loss: 0.1249\n",
            "Epoch 67/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0244 - val_accuracy: 0.9649 - val_loss: 0.1285\n",
            "Epoch 68/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0235 - val_accuracy: 0.9649 - val_loss: 0.1294\n",
            "Epoch 69/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0215 - val_accuracy: 0.9649 - val_loss: 0.1304\n",
            "Epoch 70/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0248 - val_accuracy: 0.9649 - val_loss: 0.1296\n",
            "Epoch 71/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0318 - val_accuracy: 0.9649 - val_loss: 0.1350\n",
            "Epoch 72/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0141 - val_accuracy: 0.9649 - val_loss: 0.1377\n",
            "Epoch 73/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0193 - val_accuracy: 0.9737 - val_loss: 0.1426\n",
            "Epoch 74/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0270 - val_accuracy: 0.9737 - val_loss: 0.1332\n",
            "Epoch 75/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0250 - val_accuracy: 0.9649 - val_loss: 0.1268\n",
            "Epoch 76/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0199 - val_accuracy: 0.9649 - val_loss: 0.1193\n",
            "Epoch 77/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0223 - val_accuracy: 0.9649 - val_loss: 0.1209\n",
            "Epoch 78/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0163 - val_accuracy: 0.9649 - val_loss: 0.1198\n",
            "Epoch 79/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.0240 - val_accuracy: 0.9649 - val_loss: 0.1218\n",
            "Epoch 80/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0247 - val_accuracy: 0.9737 - val_loss: 0.1199\n",
            "Epoch 81/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0184 - val_accuracy: 0.9737 - val_loss: 0.0886\n",
            "Epoch 82/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0177 - val_accuracy: 0.9737 - val_loss: 0.0825\n",
            "Epoch 83/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0100 - val_accuracy: 0.9737 - val_loss: 0.0842\n",
            "Epoch 84/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0163 - val_accuracy: 0.9737 - val_loss: 0.0857\n",
            "Epoch 85/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0215 - val_accuracy: 0.9737 - val_loss: 0.0912\n",
            "Epoch 86/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.0208 - val_accuracy: 0.9737 - val_loss: 0.0933\n",
            "Epoch 87/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.9737 - val_loss: 0.0952\n",
            "Epoch 88/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9976 - loss: 0.0116 - val_accuracy: 0.9737 - val_loss: 0.0944\n",
            "Epoch 89/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.0178 - val_accuracy: 0.9737 - val_loss: 0.0984\n",
            "Epoch 90/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.9737 - val_loss: 0.1010\n",
            "Epoch 91/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 0.0215 - val_accuracy: 0.9737 - val_loss: 0.1046\n",
            "Epoch 92/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9940 - loss: 0.0136 - val_accuracy: 0.9737 - val_loss: 0.1057\n",
            "Epoch 93/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0327 - val_accuracy: 0.9737 - val_loss: 0.1086\n",
            "Epoch 94/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9922 - loss: 0.0149 - val_accuracy: 0.9737 - val_loss: 0.1142\n",
            "Epoch 95/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9960 - loss: 0.0154 - val_accuracy: 0.9649 - val_loss: 0.1146\n",
            "Epoch 96/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9947 - loss: 0.0163 - val_accuracy: 0.9737 - val_loss: 0.1185\n",
            "Epoch 97/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0130 - val_accuracy: 0.9737 - val_loss: 0.1200\n",
            "Epoch 98/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0183 - val_accuracy: 0.9737 - val_loss: 0.1236\n",
            "Epoch 99/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0095 - val_accuracy: 0.9649 - val_loss: 0.1264\n",
            "Epoch 100/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9737 - val_loss: 0.1228\n",
            "Epoch 101/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0227 - val_accuracy: 0.9737 - val_loss: 0.1198\n",
            "Epoch 102/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0116 - val_accuracy: 0.9737 - val_loss: 0.0862\n",
            "Epoch 103/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0125 - val_accuracy: 0.9649 - val_loss: 0.0753\n",
            "Epoch 104/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0158 - val_accuracy: 0.9561 - val_loss: 0.0726\n",
            "Epoch 105/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0115 - val_accuracy: 0.9649 - val_loss: 0.0728\n",
            "Epoch 106/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0088 - val_accuracy: 0.9649 - val_loss: 0.0748\n",
            "Epoch 107/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9649 - val_loss: 0.0825\n",
            "Epoch 108/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0110 - val_accuracy: 0.9737 - val_loss: 0.0959\n",
            "Epoch 109/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0100 - val_accuracy: 0.9737 - val_loss: 0.1050\n",
            "Epoch 110/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0119 - val_accuracy: 0.9737 - val_loss: 0.1100\n",
            "Epoch 111/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9959 - loss: 0.0092 - val_accuracy: 0.9737 - val_loss: 0.1134\n",
            "Epoch 112/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0104 - val_accuracy: 0.9737 - val_loss: 0.1114\n",
            "Epoch 113/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0096 - val_accuracy: 0.9737 - val_loss: 0.1112\n",
            "Epoch 114/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9649 - val_loss: 0.1092\n",
            "Epoch 115/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0138 - val_accuracy: 0.9649 - val_loss: 0.1122\n",
            "Epoch 116/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0140 - val_accuracy: 0.9737 - val_loss: 0.1128\n",
            "Epoch 117/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0109 - val_accuracy: 0.9737 - val_loss: 0.1133\n",
            "Epoch 118/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9971 - loss: 0.0103 - val_accuracy: 0.9737 - val_loss: 0.1158\n",
            "Epoch 119/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9649 - val_loss: 0.1177\n",
            "Epoch 120/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0141 - val_accuracy: 0.9649 - val_loss: 0.1196\n",
            "Epoch 121/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0157 - val_accuracy: 0.9649 - val_loss: 0.1177\n",
            "Epoch 122/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.9649 - val_loss: 0.1198\n",
            "Epoch 123/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0083 - val_accuracy: 0.9649 - val_loss: 0.1229\n",
            "Epoch 124/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9649 - val_loss: 0.1212\n",
            "Epoch 125/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0087 - val_accuracy: 0.9649 - val_loss: 0.1200\n",
            "Epoch 126/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0145 - val_accuracy: 0.9649 - val_loss: 0.1240\n",
            "Epoch 127/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0183 - val_accuracy: 0.9649 - val_loss: 0.1325\n",
            "Epoch 128/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9561 - val_loss: 0.1342\n",
            "Epoch 129/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0094 - val_accuracy: 0.9561 - val_loss: 0.1370\n",
            "Epoch 130/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0093 - val_accuracy: 0.9649 - val_loss: 0.1364\n",
            "Epoch 131/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0078 - val_accuracy: 0.9649 - val_loss: 0.1407\n",
            "Epoch 132/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0089 - val_accuracy: 0.9649 - val_loss: 0.1404\n",
            "Epoch 133/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0116 - val_accuracy: 0.9649 - val_loss: 0.1296\n",
            "Epoch 134/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9649 - val_loss: 0.1248\n",
            "Epoch 135/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0057 - val_accuracy: 0.9649 - val_loss: 0.1273\n",
            "Epoch 136/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0055 - val_accuracy: 0.9649 - val_loss: 0.1267\n",
            "Epoch 137/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9649 - val_loss: 0.1354\n",
            "Epoch 138/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9934 - loss: 0.0125 - val_accuracy: 0.9649 - val_loss: 0.1361\n",
            "Epoch 139/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0070 - val_accuracy: 0.9649 - val_loss: 0.1335\n",
            "Epoch 140/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0062 - val_accuracy: 0.9649 - val_loss: 0.1339\n",
            "Epoch 141/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9649 - val_loss: 0.1433\n",
            "Epoch 142/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0080 - val_accuracy: 0.9649 - val_loss: 0.1324\n",
            "Epoch 143/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0080 - val_accuracy: 0.9649 - val_loss: 0.1296\n",
            "Epoch 144/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9649 - val_loss: 0.1302\n",
            "Epoch 145/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9649 - val_loss: 0.1272\n",
            "Epoch 146/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 0.9649 - val_loss: 0.1302\n",
            "Epoch 147/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.9561 - val_loss: 0.1421\n",
            "Epoch 148/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.0121 - val_accuracy: 0.9474 - val_loss: 0.1554\n",
            "Epoch 149/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9971 - loss: 0.0113 - val_accuracy: 0.9474 - val_loss: 0.1564\n",
            "Epoch 150/150\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0077 - val_accuracy: 0.9474 - val_loss: 0.1524\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train, epochs=150, verbose=1, validation_data=(X_valid, y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pd84BhFbQvO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e31900-dec4-4ac4-c9ae-c7c07f71d382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = model.predict(X_valid)\n",
        "y_pred = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2V3q6RKmQvO1"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mtFzTxTbQvO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d0d001-4bf2-4e66-d895-1f7aeb3a0f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our accuracy is 94.73684210526315%\n"
          ]
        }
      ],
      "source": [
        "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/114)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxMft4hnQvO2"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJyGU-HfQvO2"
      },
      "source": [
        "A confusion matrix represents the prediction summary in matrix form. It shows how many prediction are correct and incorrect per class. It helps in understanding the classes that are being confused by model as other class.  So, (1, 1) and (0,0) are properly predicted, benign or malignant.\n",
        "\n",
        "<img src=\"https://github.com/harmanani/AAI612/blob/main/Week3/images/3-s2.0-B9780323911979000138-f14-09-9780323911979.jpg?raw=1\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oDeSZKFlQvO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "424f0c87-ddfc-4aa2-b2e8-78f374e2530e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(cm,annot=True)\n",
        "plt.savefig('h.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eihanGqtQvO2"
      },
      "outputs": [],
      "source": [
        "chart_x = range(1,151)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Kpq4rmy2QvO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca30e69-30f3-41d0-e8e9-c0cb8334ef2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
          ]
        }
      ],
      "source": [
        "chart_y_train = history.history['loss']\n",
        "chart_y_test = history.history['val_loss']\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1BptxtECQvO3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "f08b8d24-3d5c-49f6-adb9-c648eaa1f299"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning():\n",
        "    plt.plot(chart_x, chart_y_train, 'r-',label='training error')\n",
        "    plt.plot(chart_x, chart_y_test, 'b-',\n",
        "    label='test error')\n",
        "    plt.xlabel('training epochs')\n",
        "    plt.ylabel('error')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_learning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFHmNH3jQvO3"
      },
      "source": [
        "### Observing Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VTs_qutQvO3"
      },
      "source": [
        "For each of the 5 epochs, notice the `accuracy` and `val_accuracy` scores. `accuracy` states how well the model did for the epoch on all the training data. `val_accuracy` states how well the model did on the validation data, which if you recall, was not used at all for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6TnGpcQQvO4"
      },
      "source": [
        "The model did quite well! The accuracy quickly reached close to 95%, as did the validation accuracy. We now have a model that can be used to accurately detect and classify hand-written images.\n",
        "\n",
        "The next step would be to use this model to classify new not-yet-seen handwritten images. This is called [inference](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). We'll explore the process of inference in a later exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80fe7910",
        "outputId": "45cb95aa-d195-4e0a-9d76-5e9fc93f4bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with activation: relu\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7743 - loss: 0.4951 - val_accuracy: 0.9474 - val_loss: 0.1807\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9417 - loss: 0.1848 - val_accuracy: 0.9825 - val_loss: 0.0965\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9624 - loss: 0.1278 - val_accuracy: 0.9825 - val_loss: 0.0744\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0703 - val_accuracy: 0.9825 - val_loss: 0.0664\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.0640 - val_accuracy: 0.9737 - val_loss: 0.0641\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9763 - loss: 0.0628 - val_accuracy: 0.9737 - val_loss: 0.0643\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.0614 - val_accuracy: 0.9737 - val_loss: 0.0607\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0437 - val_accuracy: 0.9825 - val_loss: 0.0587\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0463 - val_accuracy: 0.9649 - val_loss: 0.0614\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0427 - val_accuracy: 0.9737 - val_loss: 0.0573\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0373 - val_accuracy: 0.9737 - val_loss: 0.0574\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0341 - val_accuracy: 0.9737 - val_loss: 0.0589\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0245 - val_accuracy: 0.9737 - val_loss: 0.0592\n",
            "Training model with activation: sigmoid\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4987 - loss: 0.6839 - val_accuracy: 0.6404 - val_loss: 0.5578\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6892 - loss: 0.5243 - val_accuracy: 0.8947 - val_loss: 0.4118\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.3937 - val_accuracy: 0.9298 - val_loss: 0.2825\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2755 - val_accuracy: 0.9649 - val_loss: 0.1966\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.1921 - val_accuracy: 0.9561 - val_loss: 0.1494\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1523 - val_accuracy: 0.9825 - val_loss: 0.1226\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.1624 - val_accuracy: 0.9737 - val_loss: 0.1040\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.1123 - val_accuracy: 0.9912 - val_loss: 0.0922\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9750 - loss: 0.0911 - val_accuracy: 0.9912 - val_loss: 0.0828\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0937 - val_accuracy: 0.9912 - val_loss: 0.0793\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0852 - val_accuracy: 0.9912 - val_loss: 0.0729\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.0960 - val_accuracy: 0.9912 - val_loss: 0.0698\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.0921 - val_accuracy: 0.9825 - val_loss: 0.0669\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0613 - val_accuracy: 0.9825 - val_loss: 0.0636\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0693 - val_accuracy: 0.9825 - val_loss: 0.0629\n",
            "Training model with activation: softmax\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.3998 - loss: 0.6948 - val_accuracy: 0.6228 - val_loss: 0.6918\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6365 - loss: 0.6907 - val_accuracy: 0.6228 - val_loss: 0.6880\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6321 - loss: 0.6868 - val_accuracy: 0.6228 - val_loss: 0.6845\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6332 - loss: 0.6830 - val_accuracy: 0.6228 - val_loss: 0.6812\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6353 - loss: 0.6794 - val_accuracy: 0.6228 - val_loss: 0.6779\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6424 - loss: 0.6750 - val_accuracy: 0.6228 - val_loss: 0.6747\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6416 - loss: 0.6715 - val_accuracy: 0.6228 - val_loss: 0.6715\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6184 - loss: 0.6715 - val_accuracy: 0.6228 - val_loss: 0.6683\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6369 - loss: 0.6651 - val_accuracy: 0.6228 - val_loss: 0.6651\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6127 - loss: 0.6663 - val_accuracy: 0.6228 - val_loss: 0.6619\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6356 - loss: 0.6585 - val_accuracy: 0.6228 - val_loss: 0.6584\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6381 - loss: 0.6541 - val_accuracy: 0.6228 - val_loss: 0.6550\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6146 - loss: 0.6560 - val_accuracy: 0.6228 - val_loss: 0.6513\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6150 - loss: 0.6527 - val_accuracy: 0.6228 - val_loss: 0.6474\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6207 - loss: 0.6468 - val_accuracy: 0.6228 - val_loss: 0.6429\n",
            "Training model with activation: swish\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8637 - loss: 0.5303 - val_accuracy: 0.9649 - val_loss: 0.2214\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9474 - loss: 0.1880 - val_accuracy: 0.9737 - val_loss: 0.1101\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.1208 - val_accuracy: 0.9649 - val_loss: 0.0858\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0946 - val_accuracy: 0.9737 - val_loss: 0.0769\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9803 - loss: 0.0912 - val_accuracy: 0.9737 - val_loss: 0.0692\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0647 - val_accuracy: 0.9737 - val_loss: 0.0672\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9845 - loss: 0.0603 - val_accuracy: 0.9737 - val_loss: 0.0654\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9815 - loss: 0.0616 - val_accuracy: 0.9737 - val_loss: 0.0653\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0619 - val_accuracy: 0.9737 - val_loss: 0.0652\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0774 - val_accuracy: 0.9649 - val_loss: 0.0637\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0490 - val_accuracy: 0.9737 - val_loss: 0.0621\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9746 - loss: 0.0771 - val_accuracy: 0.9825 - val_loss: 0.0615\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0433 - val_accuracy: 0.9737 - val_loss: 0.0620\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.0632 - val_accuracy: 0.9825 - val_loss: 0.0626\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0525 - val_accuracy: 0.9825 - val_loss: 0.0610\n",
            "Training model with LeakyReLU\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7234 - loss: 0.6088 - val_accuracy: 0.9649 - val_loss: 0.2335\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9512 - loss: 0.2057 - val_accuracy: 0.9649 - val_loss: 0.1162\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9614 - loss: 0.1419 - val_accuracy: 0.9737 - val_loss: 0.0837\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9754 - loss: 0.0799 - val_accuracy: 0.9825 - val_loss: 0.0708\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9768 - loss: 0.0987 - val_accuracy: 0.9737 - val_loss: 0.0677\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.0728 - val_accuracy: 0.9737 - val_loss: 0.0649\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9765 - loss: 0.0770 - val_accuracy: 0.9737 - val_loss: 0.0654\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9961 - loss: 0.0339 - val_accuracy: 0.9737 - val_loss: 0.0640\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0420 - val_accuracy: 0.9649 - val_loss: 0.0653\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9948 - loss: 0.0365 - val_accuracy: 0.9649 - val_loss: 0.0650\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0343 - val_accuracy: 0.9649 - val_loss: 0.0640\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0350 - val_accuracy: 0.9737 - val_loss: 0.0608\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9918 - loss: 0.0369 - val_accuracy: 0.9737 - val_loss: 0.0671\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0328 - val_accuracy: 0.9649 - val_loss: 0.0692\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0424 - val_accuracy: 0.9737 - val_loss: 0.0669\n",
            "All models trained successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, LeakyReLU, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "\n",
        "# Define different activation functions\n",
        "activations = ['relu', 'sigmoid', 'softmax', 'swish']\n",
        "\n",
        "# Train models with different activations\n",
        "results = {}\n",
        "\n",
        "for act in activations:\n",
        "    print(f\"Training model with activation: {act}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_train.shape[1],)),  # Use the correct input shape\n",
        "        Dense(128, activation=act),\n",
        "        Dense(64, activation=act),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification output\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "    # Early Stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=15,  # Increased epochs for better training\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping]  # Apply EarlyStopping\n",
        "    )\n",
        "\n",
        "    results[act] = history.history\n",
        "\n",
        "# Train a model with Leaky ReLU separately\n",
        "print(\"Training model with LeakyReLU\")\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(128),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(64),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=15,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    verbose=1,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "results['LeakyReLU'] = history.history\n",
        "\n",
        "# Save results for analysis\n",
        "import pickle\n",
        "\n",
        "with open(\"training_results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "print(\"All models trained successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}